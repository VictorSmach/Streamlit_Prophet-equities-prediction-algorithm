{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 15\n",
    "# Amazon stock market\n",
    "ticker = \"NIO\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 496 samples, validate on 124 samples\n",
      "Epoch 1/15\n",
      "448/496 [==========================>...] - ETA: 1s - loss: 0.0244 - mean_absolute_error: 0.1249\n",
      "Epoch 00001: val_loss improved from inf to 0.01483, saving model to results\\2021-06-02_NIO-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "496/496 [==============================] - 15s 30ms/sample - loss: 0.0229 - mean_absolute_error: 0.1215 - val_loss: 0.0148 - val_mean_absolute_error: 0.1034\n",
      "Epoch 2/15\n",
      "448/496 [==========================>...] - ETA: 0s - loss: 0.0065 - mean_absolute_error: 0.0731\n",
      "Epoch 00002: val_loss improved from 0.01483 to 0.00446, saving model to results\\2021-06-02_NIO-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "496/496 [==============================] - 5s 10ms/sample - loss: 0.0065 - mean_absolute_error: 0.0739 - val_loss: 0.0045 - val_mean_absolute_error: 0.0708\n",
      "Epoch 3/15\n",
      "448/496 [==========================>...] - ETA: 0s - loss: 0.0048 - mean_absolute_error: 0.0606\n",
      "Epoch 00003: val_loss did not improve from 0.00446\n",
      "496/496 [==============================] - 4s 9ms/sample - loss: 0.0049 - mean_absolute_error: 0.0604 - val_loss: 0.0049 - val_mean_absolute_error: 0.0536\n",
      "Epoch 4/15\n",
      "448/496 [==========================>...] - ETA: 0s - loss: 0.0042 - mean_absolute_error: 0.0569\n",
      "Epoch 00004: val_loss improved from 0.00446 to 0.00378, saving model to results\\2021-06-02_NIO-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "496/496 [==============================] - 5s 9ms/sample - loss: 0.0042 - mean_absolute_error: 0.0566 - val_loss: 0.0038 - val_mean_absolute_error: 0.0529\n",
      "Epoch 5/15\n",
      "448/496 [==========================>...] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0497\n",
      "Epoch 00005: val_loss improved from 0.00378 to 0.00367, saving model to results\\2021-06-02_NIO-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "496/496 [==============================] - 4s 9ms/sample - loss: 0.0037 - mean_absolute_error: 0.0490 - val_loss: 0.0037 - val_mean_absolute_error: 0.0521\n",
      "Epoch 6/15\n",
      "448/496 [==========================>...] - ETA: 0s - loss: 0.0036 - mean_absolute_error: 0.0549\n",
      "Epoch 00006: val_loss improved from 0.00367 to 0.00357, saving model to results\\2021-06-02_NIO-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "496/496 [==============================] - 5s 10ms/sample - loss: 0.0036 - mean_absolute_error: 0.0547 - val_loss: 0.0036 - val_mean_absolute_error: 0.0522\n",
      "Epoch 7/15\n",
      "448/496 [==========================>...] - ETA: 0s - loss: 0.0034 - mean_absolute_error: 0.0477\n",
      "Epoch 00007: val_loss did not improve from 0.00357\n",
      "496/496 [==============================] - 4s 9ms/sample - loss: 0.0037 - mean_absolute_error: 0.0499 - val_loss: 0.0037 - val_mean_absolute_error: 0.0505\n",
      "Epoch 8/15\n",
      "448/496 [==========================>...] - ETA: 0s - loss: 0.0039 - mean_absolute_error: 0.0545\n",
      "Epoch 00008: val_loss did not improve from 0.00357\n",
      "496/496 [==============================] - 5s 9ms/sample - loss: 0.0038 - mean_absolute_error: 0.0535 - val_loss: 0.0036 - val_mean_absolute_error: 0.0503\n",
      "Epoch 9/15\n",
      "448/496 [==========================>...] - ETA: 0s - loss: 0.0035 - mean_absolute_error: 0.0489\n",
      "Epoch 00009: val_loss improved from 0.00357 to 0.00351, saving model to results\\2021-06-02_NIO-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "496/496 [==============================] - 5s 9ms/sample - loss: 0.0036 - mean_absolute_error: 0.0488 - val_loss: 0.0035 - val_mean_absolute_error: 0.0506\n",
      "Epoch 10/15\n",
      "448/496 [==========================>...] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0504\n",
      "Epoch 00010: val_loss did not improve from 0.00351\n",
      "496/496 [==============================] - 4s 9ms/sample - loss: 0.0033 - mean_absolute_error: 0.0508 - val_loss: 0.0036 - val_mean_absolute_error: 0.0496\n",
      "Epoch 11/15\n",
      "448/496 [==========================>...] - ETA: 0s - loss: 0.0031 - mean_absolute_error: 0.0462\n",
      "Epoch 00011: val_loss improved from 0.00351 to 0.00330, saving model to results\\2021-06-02_NIO-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "496/496 [==============================] - 5s 9ms/sample - loss: 0.0033 - mean_absolute_error: 0.0484 - val_loss: 0.0033 - val_mean_absolute_error: 0.0513\n",
      "Epoch 12/15\n",
      "448/496 [==========================>...] - ETA: 0s - loss: 0.0030 - mean_absolute_error: 0.0476\n",
      "Epoch 00012: val_loss did not improve from 0.00330\n",
      "496/496 [==============================] - 5s 9ms/sample - loss: 0.0031 - mean_absolute_error: 0.0477 - val_loss: 0.0036 - val_mean_absolute_error: 0.0490\n",
      "Epoch 13/15\n",
      "448/496 [==========================>...] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0495\n",
      "Epoch 00013: val_loss did not improve from 0.00330\n",
      "496/496 [==============================] - 4s 9ms/sample - loss: 0.0031 - mean_absolute_error: 0.0492 - val_loss: 0.0033 - val_mean_absolute_error: 0.0489\n",
      "Epoch 14/15\n",
      "448/496 [==========================>...] - ETA: 0s - loss: 0.0035 - mean_absolute_error: 0.0508\n",
      "Epoch 00014: val_loss did not improve from 0.00330\n",
      "496/496 [==============================] - 4s 9ms/sample - loss: 0.0034 - mean_absolute_error: 0.0508 - val_loss: 0.0036 - val_mean_absolute_error: 0.0595\n",
      "Epoch 15/15\n",
      "448/496 [==========================>...] - ETA: 0s - loss: 0.0036 - mean_absolute_error: 0.0548\n",
      "Epoch 00015: val_loss did not improve from 0.00330\n",
      "496/496 [==============================] - 5s 9ms/sample - loss: 0.0035 - mean_absolute_error: 0.0546 - val_loss: 0.0050 - val_mean_absolute_error: 0.0570\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-8-87357480c861>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-87357480c861>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    tensorboard --logdir=\"logs\"\u001b[0m\n\u001b[1;37m                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": [
    "tensorboard --logdir=\"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, pred_future, true_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, pred_future, true_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 15 days is 37.84$\n",
      "huber_loss loss: 0.0033035930696754686\n",
      "Mean Absolute Error: 4.474430264004575\n",
      "Accuracy score: 0.5161290322580645\n",
      "Total buy profit: 91.28000164031982\n",
      "Total sell profit: -29.890006899833686\n",
      "Total profit: 61.38999474048614\n",
      "Profit per trade: 0.49508060274585597\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2dd3hU1daH3w0hlNB7JyBVWmhKsyKIDUHFrtgu+tn1iqBey1X02u61K6JXBRUsKIogXgQFC0WC9BZAWqghodeU9f2xZsgkmTTIlGTW+zzznJkz55y1zpTf2Wfttdd2IoJhGIYROZQKtQOGYRhGcDHhNwzDiDBM+A3DMCIME37DMIwIw4TfMAwjwogKtQMFoWbNmhIbGxtqNwzDMIoVCxYs2CUitbKvLxbCHxsbS3x8fKjdMAzDKFY45zb6W2+hHsMwjAjDhN8wDCPCMOE3DMOIMIpFjN8fqampJCYmcuTIkVC7YhSCcuXK0bBhQ8qUKRNqVwwjYim2wp+YmEilSpWIjY3FORdqd4wCICIkJyeTmJhI06ZNQ+2OYUQsxTbUc+TIEWrUqGGiX4xwzlGjRg27SzOMEFNshR8w0S+G2HdmGKGnWAu/YRhGfmRkFGw7ERgzBvbtC6w/4YAJ/0kyceJEnHOsWrUq320/+ugjtm7desK2Zs6cycUXX+x3fZUqVejUqRNt2rThn//8p9/9t27dyhVXXHHC9g2juDFtGtSoAfPn579tfDzcdBOMHx9wt0KOCf9JMn78eHr37s1nn32W77YnK/x5ccYZZ7Bw4ULi4+P55JNPWLBgQZb309LSqF+/PhMmTAiIfcMIR5YuhT174IorYNeuvLedO1eXGzYE3K2QY8J/Ehw4cIDff/+d//73vzmE/8UXX6R9+/Z07NiRESNGMGHCBOLj47nuuuuIi4vj8OHDxMbGssvza4yPj+fss88G4I8//qBnz5506tSJnj17snr16gL7FBMTQ5cuXVi3bh0fffQRgwcP5pJLLqFfv35s2LCBdu3aAZCens5DDz1E+/bt6dChA2+88QYACxYs4KyzzqJLly6cf/75bNu2rQg+KcMIDUlJUKoUbN8OV18NaWm5bztnji4jQfiLbTqnL/ffD4sWFe0x4+Lg1Vfz3uabb76hf//+tGzZkurVq/Pnn3/SuXNnpk6dyjfffMO8efOoUKECKSkpVK9enTfffJOXX36Zrl275nnc1q1b88svvxAVFcX06dN59NFH+eqrrwrkd3JyMnPnzuXxxx9n/vz5zJkzhyVLllC9enU2+PyiR48ezfr161m4cCFRUVGkpKSQmprKPffcw7fffkutWrX4/PPPeeyxx/jggw8KZNswwo2kJKhTB559Fm65BR56KPf/tbfFv9FvdZuSRYkQ/lAxfvx47r//fgCuvvpqxo8fT+fOnZk+fTo333wzFSpUAKB69eqFOu7evXsZMmQIa9aswTlHampqvvv8+uuvdOrUiVKlSjFixAjatm3L/Pnz6du3r1/706dP54477iAqKuq4j8uWLWPZsmX07dsX0LuCevXqFcp3wwgndu2CWrXg5pth8WJ47TXo2FFf+7JjB6xfD6VLW4u/2JBfyzwQJCcn89NPP7Fs2TKcc6Snp+Oc48UXX0RECpS2GBUVRYYn5cA3t/3xxx/nnHPOYeLEiWzYsOF4CCgvzjjjDCZPnpxjfUxMjN/t/fkoIrRt25Y53ntewyjmJCWp8AO8/LLG/O+4A9q0ge7dM7ebN0+Xffpoh/CRI1CuXPD9DRYBjfE756o65yY451Y551Y653o456o75350zq3xLKsF0odAMWHCBG688UY2btzIhg0b2Lx5M02bNuW3336jX79+fPDBBxw6dAiAlJQUACpVqsT+/fuPHyM2NvZ4J6xvKGfv3r00aNAA0A7hQNCvXz9GjRpFmifomZKSQqtWrUhKSjou/KmpqSxfvjwg9g0jGPgKf1QUfPEFNGwIl10GvnkWc+bo+5ddpq83bw6+r8Ek0J27rwE/iEhroCOwEhgBzBCRFsAMz+tix/jx4xk0aFCWdZdffjnjxo2jf//+DBgwgK5duxIXF8fLL78MwE033cQdd9xxvHP3ySef5L777uOMM86gdOnSx4/z8MMP88gjj9CrVy/S09MD4v9tt91G48aN6dChAx07dmTcuHFER0czYcIEhg8fTseOHYmLi2P27NkBsW8YwcBX+EFTO7/9VnP1Bw2Co0d1/dy52q/XurW+LvHhHhEJyAOoDKwHXLb1q4F6nuf1gNX5HatLly6SnRUrVuRYZxQP7LszgsHRoyIg8s9/5nxv7Fh9b9o0kdRUkZgYkXvuEdmwQde/917w/Q0EQLz40dRAtvibAUnAh865hc65951zMUAdEdnmuehsA2r729k5N9Q5F++ci09KSgqgm4ZhlESSk3VZK8fEg9Czpy63bIHly+HgQY35N2gQGR28gRT+KKAz8I6IdAIOUoiwjoiMFpGuItK1lr9vzjAMIw+87UV/8uFNVtu2LTONs3t3jfM3bFjyUzoDKfyJQKKIePrLmYBeCHY45+oBeJY7A+iDYRgRSl7CX6ECVK6swj9njm7jrRQeG2st/hNGRLYDm51zrTyr+gArgEnAEM+6IcC3gfLBMIzIJS/hB231b9+uLf4ePcCb3dykSckX/kDn8d8DfOqciwb+Am5GLzZfOOduBTYBgwPsg2EYEYhX+GvW9P9+3bqwYgWsXg1DhmSuj43VVM9jxyA6OuBuhoSACr+ILAL81SfoE0i7hmEYu3ZpK75GDf/v16sHs2bpc9/BXE2aaCnnxERo1izwfoYCK9J2EpQuXZq4uDjatWvH4MGDjw/YOhF8Sy5PmjSJ559/Ptdt9+zZw9tvv11oG0899dTxMQXZ1zdo0OD4uUyaNMnv/vn5ZRjhRFISVK+uWTr+8HbwlioFvuWzYmN1WZI7eE34T4Ly5cuzaNEili1bRnR0NKNGjcryvogcL8lQGAYMGMCIEbknQJ2o8OfFAw88wKJFi/jyyy+55ZZbcvidlpaWr1+GEU5kH7yVHa/wt2sHlSplrvcKf0mO85vwFxFnnHEGa9euZcOGDbRp04Y777yTzp07s3nzZqZNm0aPHj3o3LkzgwcP5sCBAwD88MMPtG7dmt69e/P1118fP9ZHH33E3XffDcCOHTsYNGgQHTt2pGPHjsyePZsRI0awbt064uLiGDZsGAAvvfQS3bp1o0OHDjz55JPHj/Xss8/SqlUrzjvvvAKVd27Tpg1RUVHs2rWLm266iQcffJBzzjmH4cOH5+sXwCeffMJpp51GXFwct99+e8BGHhtGfuQn/HXr6rJHj6zrGzbUEFFJFv4SUaQtZHWZPaSlpTF16lT69+8PwOrVq/nwww95++232bVrFyNHjmT69OnExMTwwgsv8J///IeHH36Yv/3tb/z00080b96cq666yu+x7733Xs466ywmTpxIeno6Bw4c4Pnnn2fZsmUs8pzztGnTWLNmDX/88QciwoABA/jll1+IiYnhs88+Y+HChaSlpdG5c2e6dOmS57nMmzePUqVK4R07kZCQwPTp0yldunSWukH+/Fq5ciWff/45v//+O2XKlOHOO+/k008/5cYbbyzQ52gYRcmuXdCqVe7v16+vS9/4PmiHboMGJTvUUzKEP0QcPnyYuLg4QFv8t956K1u3bqVJkyZ09/ya5s6dy4oVK+jVqxcAx44do0ePHqxatYqmTZvSokULAK6//npGjx6dw8ZPP/3E2LFjAe1TqFKlCrt3786yzbRp05g2bRqdOnUCdIKYNWvWsH//fgYNGnS8PPSAAQNyPZdXXnmFTz75hEqVKvH5558fr9w5ePDgLHWE8vLr448/ZsGCBXTr1u3451O7tt+B2YYRcJKSwPO380vv3vDEE3D55TnfK+kpnSVD+ENRl5nMGH92fEshiwh9+/ZlfLaJPBctWlSg0s0FQUR45JFHuP3227Osf/XVVwts44EHHuChhx7KsT63ss65+TFkyBD+9a9/FXgfwwgEGRlasiGvUE/ZspDL9NTExsLvvwfEtbDAYvwBpnv37vz++++sXbsWgEOHDpGQkEDr1q1Zv34969atA8hxYfDSp08f3nnnHUAnRtm3b1+O8s7nn38+H3zwwfG+gy1btrBz507OPPNMJk6cyOHDh9m/fz/fffddkZ2XP7/69OnDhAkT2LlTB2OnpKSwsSTfLxthy+7dkJ6et/D7ZdEiSE0lNlZLM+c1VWNxxoQ/wNSqVYuPPvqIa665hg4dOtC9e3dWrVpFuXLlGD16NBdddBG9e/emSZMmfvd/7bXX+Pnnn2nfvj1dunRh+fLl1KhRg169etGuXTuGDRtGv379uPbaa+nRowft27fniiuuYP/+/XTu3JmrrrqKuLg4Lr/8cs4444wiOy9/fp166qmMHDmSfv360aFDB/r27Wtz9hohIb9Ru35ZuxY6dYLBg4ltkEp6etaa/SUJp5U7w5uuXbtKfHx8lnUrV66kTZs2IfLIOBnsuzMKw5dfavXMm24q+D6//QZnnKGzaXlmEs2fTz6BG24AYPuZg2n4yzh+mhXFmWcW2uWwwTm3QERyDKK1Fr9hGGHNq6/qtImFIb9yDX5ZsADKl4cXXqDuL1/yITez8a+SmY5swm8YRlizZQvsLGQN3xMK9SxYoGncDz/MsSdGcgOf0GzsU4UzXEwo1sJfHMJURlbsOzMKQ0aGxtl37SpcR2uhhT89Hf78EzzjXMo89RhjS91Ej5nPZRbsL0EUW+EvV64cycnJJiTFCBEhOTmZcuXKhdoVo5iQnAypqSCSOaNWQUhK0jIMZcsWcIeEBO1I8Ai/c/Bs7ddIiWmkA0RLGMU2j79hw4YkJiZi0zIWL8qVK0fDhg1D7YZRTNiyJfP5jh1Qp07B9tu16wTCPHBc+AGia1bmx2q3cs0fT+oBC9VhEN4UW+EvU6YMTb1T5hiGUSLxFf7CxPmTkk6wY9cn26xGDZi5rz/XyBMweXLh0orCnGIb6jEMo+STvcVfUPbsgWrVCmEoPl47dqMy28LVq8OcY12geXN45x2NN5UQTPgNwwhbfAdQFUb4Dx6EAlcbSU+HhQuzhHlAW/y7UkrBgw/CH3/ADz8U3IEwx4TfMIywZcsWjetHRxcu1FMo4c/WseulenVISQG55VZo2VI7eY8dK7gTYYwJv2EYYcuWLVoiuXbtwrX4Dx0CT1Ha/PFWBeiadYBr9epw9CgcSovWUWQJCfD66wV3Iowx4TcMI2zZulWFv06dALb4vR27rVtnWe2dq/ett4ALLoCLL9ZyniWg/pQJv2EYYcuWLTphSmFa/CLa4i+U8Gfr2AVt8QMMH+4Zw/XKKxrqeeSRAvsfrpjwG4YRlhw9qunzhW3xHzmi4l+gUE8uHbuQ2eIHvZDQvLl29I4ZA3PmFMyZMMWE3zCMsMQbUfGN8Rcko/LgQV0WqMW/erXu0DVHAcvjLX7wuRl47DG9BbnnHq0nUUwJqPA75zY455Y65xY55+I966o75350zq3xLAuTbWsYRoTgzeGvX19b/MeOwb59+e9XKOH3M2LXi1/hr1gRXnxR9/vwwwIYCE+C0eI/R0TifGpCjwBmiEgLYIbntWEYRha8wt+gAdStm3VdnkyfTjuWFlz4/XTsQlbhz3Knce210LOnxvr37CmAkfAjFKGeS4ExnudjgIEh8MEwjDDHO3irQQNo1Uqfr1yZxw7JyXDNNTS5rS9vcnfBYvy5dOyCXg+8pKb6vOEcvPGGdkDkNmlvmBNo4RdgmnNugXNuqGddHRHZBuBZ1va3o3NuqHMu3jkXb4XYDCPy2LJFq2tWq6YldJyD5ctz2XjSJGjbFr76ikMNmtOW5fm3+LOVYs6LgQOzhZk6d4a//U0vACtWFPSUwoZAC38vEekMXADc5Zwr8CRmIjJaRLqKSNdahZ4x2TCM4o538JZzmqHTtKkf4d+9G268ES69VONB8+ez4aK7qUkyVY7mkwaUkKDpOn46drOzdy/873/ZVo4cqbWfi2HZ5oAKv4hs9Sx3AhOB04Adzrl6AJ5lIefWMQwjEvAKv5e2bbMJ//ffQ7t2MG4cPPGE1tPp2JGk2m0BqLZlWd4GvAdr375A/kyfnm1FrVpw333w449a26EYETDhd87FOOcqeZ8D/YBlwCRgiGezIcC3gfLBMIziy9atmtHj5dRTtZGemorm3l90kfbAzpunsfboaAC212wHQOVN+Qj/6tW6bNky101G+KSezJjhZ4MePXS5eHE+ZxNeBLLFXwf4zTm3GPgDmCIiPwDPA32dc2uAvp7XhmEYxxHx3+JPTYU1a1DhB/jmmxwx+uSoOuyiBhXW5yP8q1ZBw4aaopkLN9+c+XzdOti4MdsGcXG69PpTTAjYRCwi8hfQ0c/6ZKBPoOwahlH82bMHDh/OKfygEZpT16+HUqWgceMc+x485FhMR85eNC9vI6tXZ6YL5YLnJuI4M2bALbf4rKhTB+rVg0WL8rYVZtjIXcMwwg5vKqdvqKdNG9X6hQuB9euhUSMoUybHvgcOwA/0p/SyJbB5s38DIir8fvL3ffE9fN26fuL8AJ06FbsWvwm/YRhhh+/gLS/ly0OvXjBlCrBhA8TG+t33wAH4ufxF+uL77/0b2LFD8zML0eI/91z46Sc/ZSPi4nSAweHDeR4rnDDhNwwj7PAn/KBZm0uWQNra9Zrf6Yf9+2FL5Tb6/uTJOTc4dAgeekifd+iQpx++Lf4+ffR6kSOltFMnHROQ6yCD8MOE3zCMsMNfqAdU+MtyhKgdW3MV/gMHoGIlp/XzZ8zI2hJft07LLYwbB08/DWfmPbTIV/jPO0+XOcI9xbCD14TfMIywY8sWzdQsVy7r+ubN4dxTNumLvIS/Iir8hw/Dzz/rG1Om6GCtTZs0BPT44zo6LA/KltXlsGHaj9y8uZ+0zmbNdCBXMergDVhWj2EYxomSPZXTl8Hd1sM62Fc9lsp+3j9wQHWYs87SEp2TJsH8+fDUU9o6//rrXC8a2YmKgrQ07VQGDfeMG6frjpf3KVVKj2stfsMwjBPHO+WiP85usgGAH9dmFe958+DKK2HWLKhZE22u9+0Lo0er6A8ZArNnF1j0vZQunXljcN552ocwf362jeLitPMhPb1Qxw4VJvyGYYQd3ikX/REr6zlGGcbPqk9GhjbozzwTuneHadM0LPPOO56Nr75aVfvf/9b6+b4lN0+Ac87Rw+WI83fqpBMBrF17UscPFib8hmGEFWlpmj2TW4vfbVjPnspNmPq/UrRpox2+GzfqlLibN8Pzz+u4KgCuukpHgz34YL7x/IJQo4Y27nPE+YtZB68Jv2EYYcX27TqrYW7Cz4YNRLVsyqFD2ok7frwm69x/vye2nx2/K0+cPn10yt1Dh3xWtm2rKUDFpIPXhN8wjLAit1TO46xfT/XOTdm2DeLjNZrjZx6VgHHeeToN5G+/+ayMjlbxtxa/YRhG4clt8BagKTtJSRAbS926RRK9KTS9e2vj3m8+/8KFBZsRPsSY8BuGETZs3w5vv63P/Qq/tzxmITNzipKYGK3GnCPO36mTXpS2bQuJX4XBhN8wjLDhyiszW9J+J95bv16XIRR+0HDPwoU6ze9xsnfwzpmjYwnCcEJ2E37DMMKGv/7KfF7Knzp5hT+XAm3Bok8fjeh4BwUD0NFThX7RIu2dvvtu+OUX+OKLkPiYFyb8hmGEDVWr5rPBhg06AW/t2sFwJ1e6ddOMoizhnipVtHzDwoWaavTnnzqI7NNPQ+ZnbljJBsMwwgZvRs9tt+Wywfr12toPRa+uD2XKaBTHb5z/1181zNOlC1xyiY4a3rxZ5w8IE6zFbxhGWLB7tz5efhneey+XjbzCHwacd55OA7lpk8/KLl1g5069gr35Jlx/va4fPz4kPuaGCb9hGGGBN77frFkeG23YEPKOXS99PBPIZmn133mnTtT71FNaQ+KUU3Q5blwoXMwVE37DMMKCdet0mavwp6RohkyYCH+7dtrVkCPO/8EH8OSTmeuuvRYWLw6riVpM+A3DCAvybfF7rwwtWgTFn/xwTqdjnDFDk3hy5aqrtMRnGHXymvAbhhEW7NqlCTu5ltbxVr5s3jxoPuXHBRfooLMFC/LYqHZtLQ89btzxUb2TJsGyZcHx0R8m/IZhhAX79kFlfzOrePEKf5iEekAn+SpdGiZOzGfDa6/VUcezZ5OUBFdcAcOH57OPiBYFyvN24sQIuPA750o75xY65yZ7Xjd1zs1zzq1xzn3unIvO7xiGYZR8CiT8DRuedE39oqR6dU3r/OabfDYcOFD9HjeOjz+G1FQt8paW5mfbffs0c6lUKR0HsGZNkfsdjBb/fcBKn9cvAK+ISAtgN3BrEHwwDCPMKZDwh1GYx8ugQbByJaxencdGlSrBpZciX3zBR++lUrasnq/fKs5ff613B9dfD889p5MAFDEBFX7nXEPgIuB9z2sHnAtM8GwyBhgYSB8Mwyge5Cv869aFpfBfeqkufVv9c+fqXO5ZWvTXXovbtYvHV13L+hpdeIJ/MnOmnwPOng3VqsHYsfDII555JIuWQLf4XwUeBrxBqhrAHhHxfhyJgN/pFpxzQ51z8c65+KSkpAC7aRhGqMlT+Pfv12m5wlD4GzWCrl0z4/xffKFTQY4cqVmcxzn/fHZXqM8lfEediof4J09Rdsy7OQ84bx6cdlpARycHTPidcxcDO0XEt7/b35n4LV4tIqNFpKuIdK3lt0yfYRgliTyF35vKecopQfOnMAwcqHq9dauOPK5eXdf7pu5P+TGa5kdXMOzW3ZRavpSljS/k/5bdRfrkqZkbbd+u6T6nnx5QfwPZ4u8FDHDObQA+Q0M8rwJVnXPeGkENga0B9MEwjGJCcRb+QYN0+e23Kv79+umkXN6UzRkz4PLLoVmnKoz8d3mIiiLh6c9ZSnu46srMW4NHH9U0IW+phwARMOEXkUdEpKGIxAJXAz+JyHXAz8AVns2GAN8GygfDMIoHIvkI/86duqxXL2g+FYY2bXRc2VdfaaO9cWNdt3y5Zu8MGAAtW8IPP+jgXoBe51fkYiZzqEwVrf8wbBh8+CHce2/AB6mFIo9/OPCgc24tGvP/bwh8MAwjjDh8GNLT8xD+lBRdVqsWNJ8Kg3Pa6p8xQ8+jfn2dgnfOHLjwQu0H+PHHrAk6detC5dYNGNbxR63z/O9/6xtDhwbc36AIv4jMFJGLPc//EpHTRKS5iAwWkaPB8MEwjPBl3z5d5ir8u3frnIdlywbNp8Iy0Cc/sX59reWze7cm5UyfDnXq5Nzn7LNh3MI2pH03VdNVp0/XW4MAYyN3DcMIOfkKf0pKZo9pmHL66ZmRqHr1dFTv+efrXUDDhv73OftsTVhauBAtUuQt+RlgTPgNwwg5e/fqsjgLf6lSmTn99epB+/Ya08+rwsRZZ+nSbz5/ADHhNwwj5HgnLc9V24uB8IP2zz79dMEn26pbF1q3NuE3DCMC8Qp/rtUJionwN2umI3YLM/bq7LN1tsb09IC5lQMTfsMwQo43aSdP4Q/TjJ6TpX17jfN7M1aDgQm/YRghx9vi96vtIsWmxX8ieMNCmzdnXX/gQEAKcwIm/IZhhAHJyTqwKSrKz5uHD8PRoxEn/N99p5md8fFFb9OE3zCMkJOcnE+YB0qs8HtTPRMTs66fNEkn7+rUqehtmvAbhhFyUlIiV/hr1IBy5bK2+I8dg++/h0su0dI9RY0Jv2EYISeSW/zOabjHV/hnzdJBbd5xAUVNoYTfORcTGDcMw4hkIln4QcM9vsI/aZLO1BiogbwFEn7nXE/n3Ao8Uyg65zo6594OjEuGYUQaycn5DN6CEi38jRplxvhFVPj79YMKFQJjr6At/leA84FkdUwWA2cGxiXDMCKJ1FQNa0Ryi79RI63jn56uZZ03bQps2Z4Ch3pEJFuyEUEcZ2YYRkll925d5in80dGBa/6GAY0aqejPm6eVPUFHAQcKf1mz/tjsnOsJiHMuGrgXT9jHMAzjZChwuYYAzkEbarwpnb16Za6LjQ2cvYIK/x3Aa+jE6InANOCuQDllGEbkUFLq9JwMvkXd7r5bB7K1ahU4ewUSfhHZBVwXODcMw4hU8qzMuW+flq48s2R3KfoK/xlnwJVXBtZeQbN6xjjnqvq8ruac+yBwbhmGESnkWaDttdf0yvDII0H1KdhUrZr5vGLFwNsraOduBxHZ430hIruBAAwkNgwj0sg11JOSAi+/rHMadusWdL+CiW/3RTgJfynn3PG6ec656hS8f8AwDCNXkpM1pl2pUrY3XnpJ6xU/80xI/AoVOT6HAFBQ8f43MNs5N8HzejDwbGBcMgwjkvCO2s2StLN9O7z+Olxzjc5aHgGUKaNjGoLR4i9o5+5Y51w8cC7ggMtEZEVAPTMMIyLwm7Tzr39pKeanngqFSyGhalVIStKCbYEmT+F3zlUWkX2e0M52YJzPe9VFJCXQDhqGUbLJUadn0yYYNQpuuglatAiVW0Fn0iTt0vAO4Aok+bX4xwEXAwsA8VnvPK9zHVvmnCsH/AKU9diZICJPOueaAp8B1YE/gRtE5NgJn4FhGMWa5ORso1Sf9USRn3giJP6Eiu7dYcKE/LcrCvLs3BWRi51zDjhLRJr5PJqKSH4Dio8C54pIRyAO6O+c6w68ALwiIi2A3cCtRXAehmEUU3K0+KdOhUGDoHHjkPlU0sk3q0dEBJhY2AOLcsDzsoznIWg/gfe6NgYYWNhjG4ZRMhDJJvwHD2p94vbtQ+pXSaeg6ZxznXOFTqR1zpV2zi0CdgI/AuuAPSKS5tkkES0D4W/foc65eOdcfFJSUmFNG4ZRDMgxnW5Cgi5btw6ZT5FAQYX/HFT81znnljjnljrnluS3k4iki0gc0BA4DWjjb7Nc9h0tIl1FpGutWrUK6KZhGMWJHIO3Vq3SpQl/QCloHv8FJ2NERPY452YC3YGqzrkoT6u/IbD1ZI5tGEbxJYfwL1yoCe3Nm4fMp0ggzxa/c66cc+5+YBjQH9giIhu9j3z2reWt7+OcKw+ch5Zy/hm4wrPZEODbkzwHwzCKKTmEf/JkOOssKFs2ZD5FAvmFesYAXYGlaEkzUWoAACAASURBVKv/34U4dj3gZ09IaD7wo4hMBoYDDzrn1gI1gP8W2mvDMEoEWQq0rVsHK1fCJZeE1KdIIL9Qz6ki0h7AOfdf4I+CHlhEluCnkJuI/IXG+w3DiHCylGT+6nt9cfHFIfMnUsivxZ/qfeKTiWMYhlEkZAn1rF0LlSsHds5BA8i/xd/RObfP89wB5T2vHZqqXzmg3hmGUaJJToaYGE9IPykJLIMvKOQp/CJSOliOGIYReWzalDnfrAl/8ChoHr9hGEaRs2aNT+bmrl0m/EHChN8wjJAgomH94wU4k5KgZs2Q+hQpmPAbhhEStm2DQ4c8LX4RC/UEERN+wzBCwvLlumzeHDhwAI4dM+EPEib8hmGEhAkTNKOnd2+0tQ8m/EHChN8wjKBz5Ah88QVcdpmKP2PG6BstW4bUr0jBhN8wjKDz/fewZw9cfz0wf77OunXDDdCjR6hdiwgKWp3TMAyjyPjkE6hbF87tcRhOuxHq1YPXXw+1WxGDCb9hGEElJQWmTIG77oKo557WGvzTpkHVqqF2LWIw4TcMI6hMmKAJPLe3/RXuflVDPH37htqtiMJi/IZhBJVvPtzN51WH0uq2MzXE8+yzoXYp4jDhNwwjcKSna8J+ejqIsPPNz/lgbhuu2PcBDBsGS5dCo0ah9jLisFCPYRiB4+9/h9degypVoH59aq9cyXy6kvHdD9S/MC7U3kUsJvyGYQSGmTNV9C+7DGrVQtas4V/JtzOt5d3MvNAK/4YSE37DMIqe/fvh5pu1HsPYsRATw8I/4bEu8O4zoXbOMOE3DKPoGTYMNm6EX3/1DM3V3P3oaBg8OMS+Gda5axhGETNtGrz7rsb3e/UCtBTPuHFw0UVQrVqI/TNM+A3DKEL27IFbb4U2beCZZ3j3XWjSBE4/Hfbu1RsBI/SY8BuGUXTcf78W2h8zhm9+KMf//R84B/v2wQ8/WCmecMFi/IZhFA2TJmmVzcceY05aN665Bk47DX76CcqX1wuAER4ErMXvnGvknPvZObfSObfcOXefZ31159yPzrk1nqVF/AwjXPjiC7j4Yp0aqzAkJ8PQodChAwlXP8Ell+gk6t99BxUqmOiHG4EM9aQBfxeRNkB34C7n3KnACGCGiLQAZnheG4YRao4c0VDNlCkwopB/y7vvhpQUUl4dywWXRuMcTJ1q86qEKwETfhHZJiJ/ep7vB1YCDYBLAc+sC4wBBgbKB8MwCsHYsRqfP+sseOMNmD7d72azZ8MLL2i1BRG06tpnn3FsxBP0H96Rbdtg8mTPlIpGWOJEJPBGnIsFfgHaAZtEpKrPe7tFJEe4xzk3FBgK0Lhx4y4bN24MuJ+GEdHccIOOtk1IgM6ddR7cpUtzlEvu3Rt+/12fd2m0k5lJbcloHMuNLebw3dQoJk6EAQOC776RE+fcAhHpmn19wLN6nHMVga+A+0VkX0H3E5HRItJVRLrWsvtFwwg8CQnQurX2xHpb//fdl2WTQ4fgjz80nP/eaOGNY7cTdWQ/3RPG8O2UKN56y0S/OBBQ4XfOlUFF/1MR+dqzeodzrp7n/XrAzkD6YBhGAVmzBlq00OfdusFjj+kFwCfk89tvkJoKAwfCbeU/pceObyg18hmem3gqn38Od9wRIt+NQhHIrB4H/BdYKSL/8XlrEjDE83wI8G2gfDAMo4AkJ8Pu3ZnCDyr8lStrpg8az3/uOe2wPav5FrjnHujZk+gRDzJwIFx5ZYh8NwpNIFv8vYAbgHOdc4s8jwuB54G+zrk1QF/Pa8MwQklCgi5btsxcFx0N/fvD11/Dtm388APMmgVPPC5UuO9vcPQofPQRlLZKm8WNgA3gEpHfgNyyd/sEyq5hGCfAmjW69G3xg9bbmTIF6dGDd6O/p1XT5tyROkpzNV97Lef2RrHARu4ahqEt/tKloWnTrOtPOw1mzeLoeRfxzZ62uu7v6J3A3XcH3U2jaDDhNwxDW/xNm0KZMjnf69KFV6+eR+roD3n0yTKUblhPUz9LWamv4ooJv2EY2uLPI2zze2ITNrZ9isefCKJPRsCwS7ZhRDoi2uL37djNxrJl0LZtEH0yAooJv2FEOtu3w8GDubb4DxyADRtM+EsSJvyGEen4S+X0YcUKXbZrFyR/jIBjwm8YkU5uqZweli/XpbX4Sw4m/IYR6SQk6GCtRo38vr1sGZQrB82aBdkvI2CY8BtGpLNmjdZQzmUE7vLlOoWuDdAtOZjwG0akk08q57JlFt8vaZjwG0YE8OOPWmUhBxkZsG5drh27e/bAli0W3y9p2AAuw4gAHn0UVq2CtWuhTh2fNzZv1mJrubT4771Xlyb8JQtr8RtGBLB5s+bjP/10tje8qZzZhD8jQwtvfvyxvjbhL1mY8BtGCefoUdixAypWhHffhdWrfd70pnK2bMnMmfDsszrZSq9ecPPN0LgxPP44xMaGwHEjYFioxzBKOFu26PLxx2HkSHjkES2xD2iLPyaGd76pxz33Qnq6rq5TR1v8VoutZGJfqWGUcDZv1mXnzjB8OEycCJMmwd69kJGwhsTyLbjzLkf//vDdd9rqX70ahgwx0S+pWIvfMEo4XuFv2BB69oS334ZLL9W4/f/WJzD7UCcefBBefFFz9S++OLT+GoHHrueGUcJJTNRlo0ZQoYK2+OvXh9XLU6lzaD0tLmzJv/9tA7QiCRN+wyjhbN4M1apBTIy+Pu00mD4dLu2wgSjS6XSlTZ8YaZjwG0YJZ/PmnGV42rSBCc/5T+U0Sj4m/IZRwtm8WeP7OfBJ5TQiCxN+wyjhJCbmUngzIQGqVoUaNYLukxFaTPgNowRz+DDs2pWL8HunW3Qu6H4ZoSVgwu+c+8A5t9M5t8xnXXXn3I/OuTWeZbVA2Q87MjJ0blPDCCK+GT05yKcqp1FyCWSL/yOgf7Z1I4AZItICmOF5XfJJS4NWreCBB0LtiRFh+ObwZ+HwYX3ThD8iCZjwi8gvQEq21ZcCYzzPxwADA2U/rJg2TcsivvZaLrVxDSMw+G3xr1wJ//qX3oFax25EEuyRu3VEZBuAiGxzztXObUPn3FBgKEDjxo2D5F6AGDsWqleHevXgllt0ZgvrUDOCQI4W/+zZ0K8fHDyor9u0CYlfRmgJ285dERktIl1FpGutWrVC7c6Js2cPfPMNXHMNfPIJJCfD//2fxfuNoLB5M9SsCeXLA/PnwwUX6LDd6dNhyhTo2DHULhohINjCv8M5Vw/As9wZZPvBZ8IErYt7440QF6cF0b/8EsaNC7VnRgRwPId/0SJt6deoAT/9BH36wIUXWkZPhBJs4Z8EDPE8HwJ8G2T7wWfsWGjdGrp109fDhmmx87vuyrwPN4wAsXkzxDZIhcGDoVIlFX2/o7mMSCKQ6ZzjgTlAK+dconPuVuB5oK9zbg3Q1/O65PLXX/Drr9ra97asSpeGMWM00+emmzTN0zACRGIiXH5wrCYXvPmmzahiAAHs3BWRa3J5q0+gbBY1aWnaQIqKgi5doEqVAux08CCULatNrSeeUMG/7rqs25xyCrzyCgwdCm+8AffdFxD/jcjm4EE4uPsolyx6WiuzXXJJqF0ywoSSXY//zTc1tnn4MBw5okvv89hYOPNMjXuecorf3T/4AG6/XZ+XKweXXabT0Z17rp8JKhYvhpdfhs8+045b71RGt9+u89dl57bbdDaM4cOhb1849dQiO23DAJg5E27jfars2QQj37d4vnEcJ8Ugu6Rr164SHx9f+B2vu05//eXLq3J7l2XLwooVsG2bhl7+/nd48kktVu7DuefqtHVvvqk1zMeP1ySdRo10dqKbhginbJgBL72kufoxMZquWbmy1kAZPBiaNMndvx07oF07vTDMmQPR0YU/RyPwpKdrJlZUlM5WUrFiqD3yy4ED8N57cM450KED9Ig7zKQVp1CrZwtKzZppwh+BOOcWiEjXHG+ISNg/unTpIifCmDEi774rcviwnzczMkTWrBG57TYREGnWTGT6dBERSU0VWbxYpFQpkccfz9zl8GGRzz4TubBfqlzrxskCOomAHKxcR448+ZxISkrhnfz6a7X/j3+c0DkaQWD4cP2OQKRlS5E//wy1Rzk4elSkX79MN0HkGj7VJ9Omhdo9I0QA8eJHU0Mu6gV5nKjwX3qpnmHt2iLPPCOya1fW9/ftE/n2W5Ev7vxZtldpIQIyodJNUrv0ruN/nmXLfHbYv1/k1VdFmjQRAdlVq5U8Wuc9KcthiYkRGTJE5Oef9ZpSKIYM0avMnDkndJ5GAPn4Y/0h3HGHfrkNGohER4u8/LK2EMKEESPUzddfF3nlFX0+o3RfyYiNFUlPD7V7RoiISOHPyBD56SeRCy7QM61QQeSee0TWrhV5/32ROnUyW0d1Kh+S9+s8KqkuSvZXqCU/DR0v8//wKPi2bSKPPSZSrZpu3Lu3XjHS0yUjQ+T330X+9jeRSpX07fbtRaZMKYSje/boxaR5c5EDB07oXI0AsHSpSNmyImefLXLsmK5LSspsUXTuLLJgQWh9FJGZM0Wc09+gl4QZmyTDOZEnnwyZX0boiUjh92XpUpGbbhIpUyZT7Hv21OjOrl0+rfRFi0S6ddMNunXTW3vQf9agQSKzZ+dq4+BBkQ8/FGndWhvwn3xSCAe9/95zzxX56is9mBE60tNFevQQqVlTxd6XjAyRL74QqVtXv+gHH9S7wRCwe7dI48baZsjiwsiR+rtdty4kfhnhQcQLv5fERP1PfPZZHiGZtDS9X46L09bdc8+JrF5dYBsHDoicc45qwscfF8K5V19VofHenlx9tV6Z7FY9+Lzzjn4PY8fmvs3u3SK3367bNW4s8vbbIitXnkCs78S57jqR0qVF5s7N9ka7diJnnhk0P4zwxIQ/yBw8qI1350TeeqsQO6amisyYoTFlb2ipWTO9+GzdGjB/DRFZtUrktddEpk4VqVJFpE+fgon4r79qfM97K1m7tsgVV2jAfdGigF24x41Tc08/ne2NAwf0h/fUUwGxaxQfTPhDwKFDIgMG6Kf8z3+eQEPw8GGRTz/VGDNo027gQJHJk/WuxCg61q7NvNsCje0nJBR8/4wM3f6990RuuOF4AsDxC3diYpG6u3GjXpt69PDTx/zNN2r3+++L1KZR/MhN+Et2Hn8YkJYGt96qJXtq19ZyKRUr6iMmJuuyYkWtodWokT7atYNq3jnK1qyB99+Hjz6CnTu13sott+gjr7ECRv6kpED37lo59fPPVa5r1dKieifDxo069Puee6BtW5g1S8eRnCTp6VpjbcECHTfYrFm2Dfr105r769fr2AMjYsktj9+EPwhkZMBbb8HSpTrI5uBB/8sDB3RQsZeKFeHhh+HBB/XiAMCxY/DddzpSZ9o0XdenD5x/vo4AbtvW/uyFQQQGDYLvv4eff4ZevcjI0O8h23i+E2fiRB32PWSIXrhPkhdf1AHfH36o5Z6ykJCgs7098wz84x8nbcso3kTkAK7iyP79IitWaJj58sv1jr1ePY0g5LilX79eR5i1apUZVqhQQaR/f00v2r07BGdQzHjrLf3cXnlF9u7VaE2PHpqa+/zzIkeO6Ga7d2u/7R9/aH/7pk2FtPPEE0USflm8WDPTLr88l9DhfffpBtu3n5Qdo2SAxfiLJ7Nna9opiJx6qsh33+Xyh9+0SfNH77lHpGlT3SE6WvsEvvzSMoP8cHDuYkkrU1b+rH+h1KqZcfzaGRMjct55mRdd3/Ee3ke5ciL/+U8hulqOHhVp0UJzfb1jAk6ASy7RPv/sgxFFRFsNVaqIXHPNCR/fKFmY8BdjMjI0tb+FDi6Ws88WmT8/nx3mztXWX716utPtt+cp/r/8InLWWTpObe5cn02nThV59FHtZF66NLMJXIx4/nmRTp20osaePXp9vOqSg7LCtZGt1JVW1XbIDTfoMA0QGT9e95s2TYX25ptFXnxRP4LvvtMW/8UX67a9ehWiD/jbb3WnCy7QzmQPBw6oj++/r/35I0eK3HmnyH//qy18753eq6+KONLlnftXiSxZohlDf/4pEh+vtyLXXKPZPDlyO41IxYS/BHDsmMibb4rUqqXf3DXXiPz1Vz47paVl1poZOlS+nZgu99+viScXXihy+umZNwigYw9ApHnN3fLrKUNyNnVLlxbp1EmOvf62JCzYJ1OnarTk738XGTxYSw79+mv4VDOYMCHT9ZYtMwfwja0wVNJx8ueLPx73NT1dR2EXJPsqI0NrQVWtKlK+vA77yLchn5GhG1aqJOlly8n26/8uS0f9Ji1bZN5teDN4o6M9S47I2dG/y6vlR8jPnCW7yjXI+Z34PnLkdhqRjAl/CWLvXm2Zly+vAnHPPRoSylWwMjIkaegjIiCjuU1KkS5NmmjFgb59dZzYyJFasy45WeTnh7+X5PL1JZXS8jT/kNoxB+Q/tyyRRcM+kUkdHpPF0V1EQPZSSV7jHmnFSilXTuSUU/S6ACLVq2saeyizThcv1i6P7t21KyQmRj+rVSO/VCeHDz9pG1u2iFx0kRzPAI2LE7n+em3BT54ssmFD5vdy9KhWULiyV6KM5yo5RpQIyMLobrLkmW9k1uR9MvDiVLmr82xJHf6YHOx6pqSWKXdc1FdXO03SrrhSZNQovaJ9/bWmbk6apMZ++y2og8eM8Cc34besnmLMli0618vYsZo2etllWgm6alUtH71nD+zeDUuWwBefC/+KepyHU58lo82plOrZA9q315zRdu2gTh3Yu1dTiD74ANq2Je39j5h9rCujRmmWY0aGpqNeeIHQp9IfnLvyLZrO/5xSqceQPufh7r6LPaf1Y8acCowapfN5d+kCo0ZB15x5BQFh5UrNoExM1GmN09IgPh7q1VP/S23eqGmaLVvCb79BmTInbVNEE61+/RWWLdNHYmLm+3Xrwv33w6pVmtTToQNceil0jN1L5amfc+785ym9cX3Wg5YuDZ06wRln6KN3b00xNYxCYOmcJZg9e3QK3/HjVYSyU7myTvb18DCh1mdvwLffam5pUlLmRk2aaF5pSormCj75pM5b4CEhQYcSnHuuTmtwnJ07dXzBqFE665hz0KwZ0ro1iUllWbzEcfiIo1nzUrRv74gu55nB5uBB2LdPLzpPPgk1axb4fHfs0GmLy5SBFi1Uwxs3hh9/hMmTdZuoKJ1f59N39tElbZ5e1M4+GwYO1CvhwoW5TsBTFOzZA8uX6+OrrzIzb//xD820zEJamn4nGzbAoUM64OPaa/UqaxgngQl/BHDkiAr0gQM68KtqVV3mOmZo5069ACxZArNnqziOHKnT9BWWtDRVt/h4bfKuWQNpaaSnZZC0Q9i9WyhTOoPatYRKFQUXE6ODE+bNU4F7+mm9OvlcbHw5dkyvKxs2wOuvw5QpOpPg2rVq6uhRoW5dx+23w603HKPBTx9T6u03dYRT9t/4p5+qsAaRP/7Qj/nWW20+FCN4mPAbIWXBArjjDr0unHcePPCAjjOqvn0F5YbfS/nfZyD16sH9D7C0w3VMnFeflSt18OvGjbB9e6Z+R0XBU8MO8ti5c2DWLGTWLFXWU9vi2p6qMZeNG6FzZxgwAHr00NnN5s/XW4SBA0P7YRhGkDDhN0JOejq8+y48+qjeXGQi9GEGj7jn6SMzAPiNXvxW/VISWlwEbdrQuImjSRONSMU13EX1s9rr1aBUKRX400/Xq8rOnVrvYsQI6N/fmtdGRGPCb4QNe/dq2GPNGg31x8Rox+vatVBq9UoGl/qK9glfEbVske4QGwsXXggXXaQTyn78sU5iP3as9pJWrhzS8zGMcCWshN851x94DSgNvC8iz+e1vQl/hJKYqDV0pkzRFKFDh7TDIipKU2USEqxFbxh5kJvwB72al3OuNPAW0BdIBOY75yaJyIpg+2KEOQ0baofv0KHac/3LLzB1qt4mXHutib5hnCChKON4GrBWRP4CcM59BlwKmPAbuVOunJYb7tcv1J4YRrGnVAhsNgA2+7xO9KwzDMMwgkAohN/f/XmOjgbn3FDnXLxzLj7Jd6CRYRiGcVKEQvgTgUY+rxsCW7NvJCKjRaSriHStZUPVDcMwioxQCP98oIVzrqlzLhq4GpgUAj8MwzAikqB37opImnPubuB/aDrnByKyPNh+GIZhRCohmZxVRL4Hvg+FbcMwjEgnFKEewzAMI4SY8BuGYUQYxaJWj3MuCdgYRJM1gV1BtGe2Q2s71PbNttkOFE1EJEdaZLEQ/mDjnIv3V9/CbJdM26G2b7bNdrCxUI9hGEaEYcJvGIYRYZjw+2e02Y4o26G2b7bNdlCxGL9hGEaEYS1+wzCMCMOE3zAMI9IQkWL/QKt9/gysBJYD93nWVwd+BNZ4ltU861sDc4CjwEPZjnUfsMxznPvzsNkfWA1sANb52J4ArEVLTc8Msm3veY8G0oJsex2wCFgKHAEOBMD2B8BOz7a+3/kqz2ONZ93Pfs79OmCJ5zEb6OjnnNYCI/KwP8Rz3PUeu95zn4bOMeE952Da9n7nUz32g2V7JVpp1/udHwN2B8D2D8AeYDpZ/+P/BOZ5fnfbC3nex39H+ejKif7Hi9K2388HeAM4cMKaeaI7htMDqAd09jyvBCQApwIvej80YATwgud5baAb8Cw+IgS0Q0WlAlrHaDrQwo+90p4fQjOgsY+9SuhAs/OAvcDTQbadAAz2/DiPhsC29zNfCtxYlLY9254JdPZs7/udvwIkeezPAmb6OfeeZP4xLwDm+TmnaGAxcKof29WBvzzL1qjoVfOc+yaPb8fw/3sLpO0E4F50BrvtIbDt/c4TPZ9Bkdn2bNsHuAQVVt//+H7g7x7bc4H/K4jt7L+jPDTlZP7jRWk7x+cDdAU+5iSEv0SEekRkm4j86Xm+H70yN0CndBzj2WwMMNCzzU4RmQ+kZjtUG2CuiBwSkTRURAb5MXl8+kgR2QR8CFzqsb0InWymAvB5kG2vBB4DyqIt/mDbbuCx1Qj4pohtIyK/ACme58e/c+BCYIHHfgN0jofs5z5bRHZ71s/12cb3nI4B3qlAs3M+8KOIpIjIKmAK0N9z7gvRzzwK/7+3QNpOAIYC5dGWcTBte7/zK9Df/K9FbBsRmYGK/FGf7/sAKojLPPuN9NgsiO0sv6M8OJn/eFHazvL5eOYsfwl4OJ9j5EmJEH5fnHOxQCf0NrCOiGwDFQq01ZkXy4AznXM1nHMVUEFp5Gc7v9NHZrNdGtgRZNtnoj+SmnhmNQvBeTcApovIviK2nRf10NbYPPTca0Ce534rGhrJ9Zz87FOQc3cF+L0Vte0zgefQc04Lsm3vedcDxotSlLZzIw7VrjlAHbRF3KCAtgtKUf3Hi8y25/ndwCTv7+xECUlZ5kDhnKsIfIXGifc552+Wx9wRkZXOuRfQ28oD6A8qzc+m/g4cFWLbk9BY58vobWcwbfuedzQwPgC2/eL5zisANxXkc3fOnYP+GXt7V/lzy9+uftaVoRDfeQBsfw+sFpFxzrlRQbZd4O/8JGz7O1ZF4CNgV7bP3O/+fmwXlJP+jxexbXHO1UdDuWcX8ng5KDEtfuec98f4qYh87Vm9wzlXz/N+PbRTJU9E5L8i0llEzkRvydY45xo55xZ5HneQc/rIxsC52Wyno62RYNmeh8Ze1wIxQAXn3Npgnrdzrgb6m1oQgPPOgc93noK2/kCLXyX7s++c6wC8j96yJ3tW+50K1Dl3uo/9Abmc+9Vk/c4lt99bgGyvQFuhG9BQT0vn3MxgnrdzriP6W98agPPOgs/3PQYo45yLQlvcHT37F8S2X4r6P17Etr3T03YCmgNrPd95Befc2ryOnSvZg/7F8YFeIccCr2Zb/xJZO9tezPb+U+TMMKntWTZGM0Wq+bEXhXZ4NUVjjSnA2GzbZO/4Cabtl8jauRsU28AdaOimyD9zn21jPTaOf+fZvudZwKzs9j3HXgv0zOecFgNt/ditjma1VPM89gPvZNsme+duMG2/S9bO3aDYBp4Hfg/EeftsfzYwGZ//OPAlegF6CY2j31kQ29l/R3nYPOH/eABs5/bdRHxWT2/0Vm8J2vGyCI0V1wBmoOlWM4Dqnu3rolfVfWiHWCJQ2fPer2hLajHQJw+bF6Ida1uy2U5EW51paOri3iDa9j1vbzpnMG0vQW9FA/WZjwe2oR3EO33sL0UFaQse4fdj/3003dDra7yfc1oHPJaH/VvQP3RitnPf4fnOM9BU1uQg2vZ+53FkpnMG0/Y2oHsu33lR2P4Vzdg66rH9l+dYK9B0x788n//aQtj2/R0lArcW8X+8KG3n+vlwEsJvJRsMwzAijBIT4zcMwzAKhgm/YRhGhGHCbxiGEWGY8BuGYUQYJvyGYRgRRokauWsYRYFzLh1NES2DpuyNQfPHM0LqmGEUESb8hpGTwyISB+Ccqw2MA6oAT4bUK8MoIizUYxh5ICI70eqXdzsl1jn3q3PuT8+jJ4Bz7mPn3PEKk865T51zA5xzbZ1zf3iG4y9xzrUI1bkYhhcbwGUY2XDOHRCRitnW7Ubr0e8HMkTkiEfEx4tIV+fcWcADIjLQOVcFHbHZAp0rYK6IfOopZlZaRA4H94wMIysW6jGMguGtmFgGeNM5F4cW6WoJICKznHNveUJDlwFfiUiac24O8JhzriHwtYisCYXzhuGLhXoMIx+cc81Qkd8JPEBmRciuaBEtLx+j0+7djE7cgYiMAwYAh4H/OefODZ7nhuEfE37DyAPnXC1gFPCmaFy0CrDNk+FzAzoZh5ePgPsBRGS5Z/9mwF8i8jo6Z0KH4HlvGP6xUI9h5KS8c24RmemcHwP/8bz3NvCVc24wOvn3Qe9OIrLDObcSnXbSy1XA9c65VHSinKeD4L9h5Il17hpGEeF06sil6KTge0Ptj2HkhoV6DKMIcM6dh04i84aJvhHuWIvfMAwjwrAWv2EYRoRhwm8YhhFhmPAbhmFEGCb8hmEYEYYJv2EYRoTx/4gn5+S9qQAAAAJJREFUxS4WoJN+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 open       high        low      close   adjclose     volume  \\\n",
      "2021-03-18  43.299999  44.259998  41.450001  41.630001  41.630001   71159900   \n",
      "2021-03-31  38.959999  39.250000  37.450001  38.980000  38.980000   98298400   \n",
      "2021-04-06  38.830002  40.389999  38.419998  40.000000  40.000000   67969400   \n",
      "2021-04-16  34.689999  36.540001  34.060001  36.090000  36.090000   84477400   \n",
      "2021-04-22  38.990002  40.450001  38.490002  39.570000  39.570000  115802700   \n",
      "2021-04-23  40.200001  41.200001  39.540001  41.080002  41.080002   70342400   \n",
      "2021-04-26  41.959999  43.220001  40.860001  42.619999  42.619999   88233500   \n",
      "2021-04-28  40.740002  41.950001  40.439999  41.189999  41.189999   57639600   \n",
      "2021-04-29  41.380001  41.490002  38.730000  38.990002  38.990002   82660700   \n",
      "2021-05-04  38.990002  39.320000  36.919998  37.930000  37.930000   78256800   \n",
      "\n",
      "           ticker  adjclose_15  true_adjclose_15  buy_profit  sell_profit  \n",
      "2021-03-18    NIO    43.823509         38.119999   -3.510002     0.000000  \n",
      "2021-03-31    NIO    39.897495         39.570000    0.590000     0.000000  \n",
      "2021-04-06    NIO    40.067257         41.209999    1.209999     0.000000  \n",
      "2021-04-16    NIO    38.830170         36.939999    0.849998     0.000000  \n",
      "2021-04-22    NIO    38.566410         31.219999    0.000000     8.350000  \n",
      "2021-04-23    NIO    38.917782         33.419998    0.000000     7.660004  \n",
      "2021-04-26    NIO    39.470318         33.810001    0.000000     8.809998  \n",
      "2021-04-28    NIO    40.465500         33.459999    0.000000     7.730000  \n",
      "2021-04-29    NIO    40.725388         34.330002   -4.660000     0.000000  \n",
      "2021-05-04    NIO    40.736984         36.070000   -1.860001     0.000000  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.tail(10))\n",
    "# save the final dataframe to csv-results folder\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a4917cd2690d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
